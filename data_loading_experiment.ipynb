{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "class Dataset:\n",
    "    _log_mfb_shape = (None, 64)\n",
    "    def __init__(self, annotations_path, dataset_path, ytids_path,\n",
    "                 class_associations=(('speech',0),('music',1),('noise',2)),\n",
    "                 load_data=True):\n",
    "        self.annotations = pd.read_csv(annotations_path).set_index('ytid')\n",
    "        self.dataset_path = dataset_path\n",
    "        with open(ytids_path, 'r') as f:\n",
    "            self.ytids = json.load(f)\n",
    "        self.class_associations = dict(class_associations)\n",
    "        self.reverse_class_associations = dict((v,k) for k,v in class_associations)\n",
    "        \n",
    "        if load_data:\n",
    "            self.load_data()\n",
    "    \n",
    "    def load_data(self):\n",
    "        self.data = {}\n",
    "        with zipfile.ZipFile(self.dataset_path, 'r') as zf:\n",
    "            for ytid in tqdm(self.ytids, desc='Loading data'):\n",
    "                data = {}\n",
    "                with zf.open(self.annotations.loc[ytid,'log_mfb_path']) as f:\n",
    "                    data['log_mfb'] = np.load(f)\n",
    "                \n",
    "                self.data[ytid] = (data, self.class_associations[\n",
    "                                       self.annotations.loc[ytid,'plausible_superclass']])\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        ytid = self.ytids[index]\n",
    "        data_without_ytid, label = self.data[ytid]\n",
    "        data = {'ytid':ytid}\n",
    "        data.update(data_without_ytid)\n",
    "        return data, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    @property\n",
    "    def tf_dataloader(self):\n",
    "        try:\n",
    "            return self._tf_dataloader\n",
    "        except AttributeError:\n",
    "            import tensorflow as tf\n",
    "            \n",
    "            _data = self.data\n",
    "            _log_mfb_shape = self._log_mfb_shape\n",
    "            def _load_data(ytid):\n",
    "                data, label = _data[ytid.numpy().decode('utf-8')]\n",
    "                log_mfb = data['log_mfb']\n",
    "                return log_mfb, label\n",
    "            \n",
    "            @tf.function\n",
    "            def _load_data_tf(ytid):\n",
    "                log_mfb, label = tf.py_function(_load_data, [ytid], [tf.float32, tf.int32])\n",
    "                log_mfb.set_shape(_log_mfb_shape)\n",
    "                label.set_shape(())\n",
    "                return (\n",
    "                    {\n",
    "                        'ytid':ytid,\n",
    "                        'log_mfb': log_mfb\n",
    "                    },\n",
    "                    label\n",
    "                )\n",
    "            self._tf_dataloader = _load_data_tf\n",
    "            return self._tf_dataloader\n",
    "    \n",
    "    def get_shuffled_tf_dataset(self, ytids=None):\n",
    "        if ytids is None:\n",
    "            ytids = self.ytids\n",
    "        return tf.data.Dataset.from_tensor_slices(ytids).shuffle(len(ytids)).map(self.tf_dataloader)\n",
    "    \n",
    "    def get_unshuffled_tf_dataset(self, ytids=None):\n",
    "        if ytids is None:\n",
    "            ytids = self.ytids\n",
    "        return tf.data.Dataset.from_tensor_slices(ytids).map(self.tf_dataloader)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 100%|██████████| 7841/7841 [00:09<00:00, 784.73it/s]\n"
     ]
    }
   ],
   "source": [
    "annotations_path = 'train_test_splits/train_dataset.csv.zip'\n",
    "dataset_path = r'G:\\datasets\\audioset-derived.zip'\n",
    "ytids_path = 'train_test_splits/train_ytids.json'\n",
    "\n",
    "dataset = Dataset(annotations_path, dataset_path, ytids_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'log_mfb': array([[-12.657357 , -11.910873 , -12.428922 , ..., -10.195707 ,\n",
       "          -10.186556 , -10.161953 ],\n",
       "         [-10.5030575, -10.368566 , -10.445654 , ..., -11.005456 ,\n",
       "          -11.021426 , -11.006858 ],\n",
       "         [-10.477143 , -10.238664 , -10.129091 , ..., -11.818546 ,\n",
       "          -11.803687 , -11.785731 ],\n",
       "         ...,\n",
       "         [-11.223254 , -10.959818 , -10.6100025, ..., -11.41233  ,\n",
       "          -11.402614 , -11.389905 ],\n",
       "         [-11.532803 , -11.399852 , -10.256641 , ..., -12.986043 ,\n",
       "          -12.9783125, -12.954549 ],\n",
       "         [-11.877029 , -11.344776 , -10.755081 , ..., -11.223252 ,\n",
       "          -11.207252 , -11.183005 ]], dtype=float32)},\n",
       " 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data['--BfvyPmVMo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'ytid': '-OhudZ743CE',\n",
       "  'log_mfb': array([[-14.89137  , -12.728969 , -12.116203 , ...,  -7.0896773,\n",
       "           -7.196857 ,  -8.67631  ],\n",
       "         [-10.76857  , -10.449691 , -10.842775 , ...,  -6.947009 ,\n",
       "           -7.0724125,  -8.099452 ],\n",
       "         [ -9.930698 ,  -7.9328694,  -7.560336 , ...,  -7.804921 ,\n",
       "           -8.327517 ,  -8.520834 ],\n",
       "         ...,\n",
       "         [-12.839853 , -11.126363 ,  -9.748734 , ...,  -8.104726 ,\n",
       "           -7.857449 ,  -7.464834 ],\n",
       "         [-10.298605 ,  -8.610804 ,  -7.6734467, ...,  -8.199435 ,\n",
       "           -9.86635  ,  -9.537319 ],\n",
       "         [-11.363624 ,  -9.043201 ,  -7.110422 , ...,  -8.247557 ,\n",
       "          -10.945918 , -10.742892 ]], dtype=float32)},\n",
       " 0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'ytid': <tf.Tensor: shape=(), dtype=string, numpy=b'Wk9rfiU9wvg'>,\n",
       "  'log_mfb': <tf.Tensor: shape=(891, 64), dtype=float32, numpy=\n",
       "  array([[-4.9784822, -3.838155 , -5.765702 , ..., -3.0246427, -2.0652351,\n",
       "          -2.985682 ],\n",
       "         [-5.0928216, -4.1160746, -6.061986 , ..., -2.8219302, -2.1946497,\n",
       "          -2.9094625],\n",
       "         [-5.120795 , -4.250414 , -6.435459 , ..., -2.6672957, -2.7416472,\n",
       "          -2.9809673],\n",
       "         ...,\n",
       "         [-7.645954 , -6.160941 , -6.194725 , ..., -1.5784578, -2.2365365,\n",
       "          -3.4383805],\n",
       "         [-6.043252 , -5.870902 , -5.2462025, ..., -1.4150183, -1.833616 ,\n",
       "          -2.6609511],\n",
       "         [-5.5630746, -5.4060726, -4.8932343, ..., -1.5111382, -2.098419 ,\n",
       "          -2.5488796]], dtype=float32)>},\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=1>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "train_dataset = dataset.get_shuffled_tf_dataset()\n",
    "\n",
    "next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.88 s ± 35.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "def _dataset_timer():\n",
    "    for e in train_dataset:\n",
    "        pass\n",
    "\n",
    "%timeit _dataset_timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomWindow:\n",
    "    def __init__(self, window_size, features, pad_value):\n",
    "        self.window_size = window_size\n",
    "        self.features = features\n",
    "        self.pad_value = pad_value\n",
    "        \n",
    "    def __call__(self, data, label):\n",
    "        data_out = data.copy()\n",
    "        \n",
    "        data_len = tf.shape(data_out[self.features[0]])[0]\n",
    "        \n",
    "        pad_size = tf.maximum(0, self.window_size - data_len)\n",
    "        for feature in self.features:\n",
    "            data_out[feature] = tf.pad(data_out[feature], [[pad_size,0]]+[[0, 0]]*(data[feature].shape.rank-1),\n",
    "                                       constant_values=self.pad_value)\n",
    "        \n",
    "        data_len = data_len + pad_size\n",
    "        \n",
    "        start_idx = tf.random.uniform((), 0, data_len-self.window_size+1, dtype=tf.int32)\n",
    "        end_idx = start_idx + self.window_size\n",
    "        \n",
    "        window = tf.stack([start_idx, end_idx], axis=0)\n",
    "        data_out['window'] = window\n",
    "        \n",
    "        for feature in self.features:\n",
    "            data_out[feature] = data_out[feature][start_idx:end_idx]\n",
    "        return data_out, label\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'ytid': <tf.Tensor: shape=(), dtype=string, numpy=b'Pef6g19i5iI'>,\n",
       "  'log_mfb': <tf.Tensor: shape=(200, 64), dtype=float32, numpy=\n",
       "  array([[-6.844574 , -5.051794 , -5.6503344, ..., -4.3814936, -4.917168 ,\n",
       "          -5.85741  ],\n",
       "         [-7.329627 , -5.132898 , -5.916989 , ..., -4.578798 , -5.0970182,\n",
       "          -5.8394337],\n",
       "         [-7.484717 , -5.678336 , -5.8584743, ..., -5.2393026, -5.5340085,\n",
       "          -6.196355 ],\n",
       "         ...,\n",
       "         [-7.4337907, -5.723109 , -6.7144737, ..., -5.6403174, -5.819802 ,\n",
       "          -6.449281 ],\n",
       "         [-7.0909367, -5.585424 , -6.1685767, ..., -5.3362393, -5.8842244,\n",
       "          -6.804651 ],\n",
       "         [-6.9376855, -6.548622 , -6.2792115, ..., -5.288309 , -6.1700425,\n",
       "          -6.9629073]], dtype=float32)>,\n",
       "  'window': <tf.Tensor: shape=(2,), dtype=int32, numpy=array([145, 345])>},\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=2>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_window = RandomWindow(window_size=200, features=['log_mfb'], pad_value=-16.)\n",
    "\n",
    "window_dataset = train_dataset.map(random_window)\n",
    "\n",
    "next(iter(window_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.844574 , -5.051794 , -5.6503344, ..., -4.3814936, -4.917168 ,\n",
       "        -5.85741  ],\n",
       "       [-7.329627 , -5.132898 , -5.916989 , ..., -4.578798 , -5.0970182,\n",
       "        -5.8394337],\n",
       "       [-7.484717 , -5.678336 , -5.8584743, ..., -5.2393026, -5.5340085,\n",
       "        -6.196355 ],\n",
       "       ...,\n",
       "       [-7.4337907, -5.723109 , -6.7144737, ..., -5.6403174, -5.819802 ,\n",
       "        -6.449281 ],\n",
       "       [-7.0909367, -5.585424 , -6.1685767, ..., -5.3362393, -5.8842244,\n",
       "        -6.804651 ],\n",
       "       [-6.9376855, -6.548622 , -6.2792115, ..., -5.288309 , -6.1700425,\n",
       "        -6.9629073]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data['Pef6g19i5iI'][0]['log_mfb'][145:345]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
