{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\Projects\\audioset_coarse_grained_classification\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded from: models/audioset\\swishnetv2_ws100_bw20_mw16_vf4_adamw2_f\\checkpoint\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from lib.training.training import read_config_from_file\n",
    "from lib.training.importer import import_scheme\n",
    "\n",
    "config_file = r'models\\audioset\\swishnetv2_ws100_bw20_mw16_vf4_adamw2_f\\config_input.yaml'\n",
    "config = read_config_from_file(config_file)\n",
    "# config['distributed'] = False\n",
    "config['dataset_path'] = 'G:/datasets/audioset-derived.zip'\n",
    "SCHEME = import_scheme(config['scheme'])\n",
    "\n",
    "training = SCHEME(config)\n",
    "training.load_checkpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1568/1568 [00:01<00:00, 1371.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-6.3940e-03, -8.0824e+00, -5.1053e+00]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "training.model.eval()\n",
    "data = training.val_dataset[0]\n",
    "x = torch.from_numpy(data['log_mfb'][None,...]).cuda()\n",
    "x = {'log_mfb': x}\n",
    "with torch.no_grad():\n",
    "    pred = training.model(x)\n",
    "\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.85 ms ± 40.3 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "training.model.eval()\n",
    "# data = training.val_dataset[0]\n",
    "# x = torch.from_numpy(data['log_mfb'][None,...]).cuda()\n",
    "x = torch.randn(1, 100, 64).cuda()\n",
    "x = {'log_mfb': x}\n",
    "with torch.no_grad():\n",
    "    %timeit training.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.87 ms ± 92.5 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "training.model.eval()\n",
    "# data = training.val_dataset[0]\n",
    "# x = torch.from_numpy(data['log_mfb'][None,...]).cuda()\n",
    "x = torch.randn(1, 200, 64).cuda()\n",
    "x = {'log_mfb': x}\n",
    "with torch.no_grad():\n",
    "    %timeit training.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.87 ms ± 27.1 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "training.model.eval()\n",
    "# data = training.val_dataset[0]\n",
    "# x = torch.from_numpy(data['log_mfb'][None,...]).cuda()\n",
    "x = torch.randn(1, 400, 64).cuda()\n",
    "x = {'log_mfb': x}\n",
    "with torch.no_grad():\n",
    "    %timeit training.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15 ms ± 82.8 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "cpu_model = training.model.cpu()\n",
    "# data = training.val_dataset[0]\n",
    "# x = torch.from_numpy(data['log_mfb'][None,...]).cuda()\n",
    "x = torch.randn(1, 100, 64)\n",
    "x = {'log_mfb': x}\n",
    "with torch.no_grad():\n",
    "    %timeit cpu_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.52 ms ± 304 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "cpu_model = training.model.cpu()\n",
    "# data = training.val_dataset[0]\n",
    "# x = torch.from_numpy(data['log_mfb'][None,...]).cuda()\n",
    "x = torch.randn(1, 200, 64)\n",
    "x = {'log_mfb': x}\n",
    "with torch.no_grad():\n",
    "    %timeit cpu_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.86 ms ± 152 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "cpu_model = training.model.cpu()\n",
    "# data = training.val_dataset[0]\n",
    "# x = torch.from_numpy(data['log_mfb'][None,...]).cuda()\n",
    "x = torch.randn(1, 400, 64)\n",
    "x = {'log_mfb': x}\n",
    "with torch.no_grad():\n",
    "    %timeit cpu_model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 64])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['log_mfb'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'log_mfb': tensor([[ -7.8278,  -7.4178,  -7.0903,  ...,  -6.4125,  -6.4606,  -6.4250],\n",
       "         [ -8.6826,  -8.3862,  -8.5069,  ...,  -8.2381,  -9.7233, -10.1630],\n",
       "         [ -7.4627,  -7.0683,  -6.9251,  ...,  -8.2676,  -9.3752,  -9.2484],\n",
       "         ...,\n",
       "         [ -7.9848,  -7.7456,  -7.5762,  ...,  -7.4857,  -8.7206,  -9.4450],\n",
       "         [ -8.5150,  -8.0476,  -8.0964,  ...,  -7.8460,  -8.5122,  -9.2318],\n",
       "         [ -8.6083,  -8.2983,  -8.0087,  ...,  -6.8229,  -7.9620,  -9.2039]],\n",
       "        device='cuda:0')}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:11<00:00,  7.60it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "training.model.eval()\n",
    "dataset = training.val_dataset\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "preds = []\n",
    "labels = []\n",
    "with torch.no_grad():\n",
    "    for data in tqdm(dataloader):\n",
    "        x = data['log_mfb'].cuda()\n",
    "        y = data['label']\n",
    "        pred = training.model({'log_mfb': x})\n",
    "        pred = torch.softmax(pred, dim=-1)\n",
    "        \n",
    "        preds.append(pred.cpu().numpy())\n",
    "        labels.append(y.numpy())\n",
    "\n",
    "preds = np.concatenate(preds)\n",
    "labels = np.concatenate(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.87%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pred_cls = np.argmax(preds, axis=-1)\n",
    "accuracy = accuracy_score(labels, pred_cls)\n",
    "print(f'Accuracy: {accuracy:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.1466093e-01, 9.3000876e-03, 7.6038919e-02],\n",
       "       [9.3254727e-01, 3.7071428e-03, 6.3745573e-02],\n",
       "       [9.2739975e-01, 1.9905164e-03, 7.0609689e-02],\n",
       "       ...,\n",
       "       [9.7287548e-01, 4.7671713e-04, 2.6647929e-02],\n",
       "       [9.4855469e-01, 3.8754931e-03, 4.7569837e-02],\n",
       "       [9.5927858e-01, 2.6127147e-03, 3.8108759e-02]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded from: models/audioset\\vgg16_ws200_ll64_vf4_0\\checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:11<00:00,  7.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded from: models/audioset\\vgg16_ws200_ll64_vf4_1\\checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:11<00:00,  7.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded from: models/audioset\\vgg16_ws200_ll64_vf4_2\\checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:11<00:00,  7.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded from: models/audioset\\vgg16_ws200_ll64_vf4_3\\checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:11<00:00,  7.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded from: models/audioset\\vgg16_ws200_ll64_vf4_4\\checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:11<00:00,  7.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded from: models/audioset\\vgg16_ws200_ll64_vf4_5\\checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:11<00:00,  7.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded from: models/audioset\\vgg16_ws200_ll64_vf4_6\\checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:11<00:00,  7.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint loaded from: models/audioset\\vgg16_ws200_ll64_vf4_7\\checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [00:11<00:00,  7.50it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "from lib.training.training import read_config_from_file\n",
    "from lib.training.importer import import_scheme\n",
    "from collections import defaultdict\n",
    "\n",
    "all_preds = defaultdict(list)\n",
    "\n",
    "for ii in range(8):\n",
    "    config_file = f'models/audioset/vgg16_ws200_ll64_vf4_{ii}/config_input.yaml'\n",
    "    config = read_config_from_file(config_file)\n",
    "    # config['distributed'] = False\n",
    "    config['dataset_path'] = 'G:/datasets/audioset-derived.zip'\n",
    "    SCHEME = import_scheme(config['scheme'])\n",
    "\n",
    "    training = SCHEME(config)\n",
    "    training.load_checkpoint()\n",
    "    training.model.eval()\n",
    "    config = training.config\n",
    "    dataset_config, dataset_class = training.get_dataset_config()\n",
    "    dataset = dataset_class(**dataset_config, \n",
    "                            include_ytid = True, \n",
    "                            include_window=True,\n",
    "                            ytid_keys=[str(k) for k in \n",
    "                                        config.val_folds])\n",
    "    dataset.load_data()\n",
    "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "    # preds = {}\n",
    "    labels = {}\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(dataloader):\n",
    "            ytids = data['ytid']\n",
    "            windows = data['window'].numpy()\n",
    "            x = data['log_mfb'].cuda()\n",
    "            y = data['label']\n",
    "            pred = training.model({'log_mfb': x})\n",
    "            pred = torch.softmax(pred, dim=-1)\n",
    "            \n",
    "            pred = pred.cpu().numpy()\n",
    "            y = y.numpy()\n",
    "            \n",
    "            for ytid, window, pred_, label_ in zip(ytids, windows, pred, y):\n",
    "                all_preds[ytid, tuple(window)].append((pred_))\n",
    "                labels[ytid, tuple(window)] = label_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "for k, label_ in labels.items():\n",
    "    preds = np.stack(all_preds[k],0).mean(0)\n",
    "    pred_cls = np.argmax(preds, axis=-1)\n",
    "    y_true.append(label_)\n",
    "    y_pred.append(pred_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.34983647e-01, 6.10195892e-03, 1.58914492e-01],\n",
       "       [8.66233885e-01, 1.29087386e-03, 1.32475227e-01],\n",
       "       [8.78881991e-01, 1.23626203e-03, 1.19881764e-01],\n",
       "       ...,\n",
       "       [9.77021098e-01, 6.07912429e-04, 2.23710835e-02],\n",
       "       [9.69656825e-01, 3.35614826e-03, 2.69870516e-02],\n",
       "       [9.60859239e-01, 2.84049870e-03, 3.63002904e-02]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_preds = np.mean(all_preds,axis=0)\n",
    "ensemble_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.20%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10904"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.__len__()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
